{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca02b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b32ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SPAM text message 20170820 - Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93eaf7c",
   "metadata": {},
   "source": [
    "Putting in an extra  column which will give each categories a number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7eec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ids'] = df['Category'].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd409cd4",
   "metadata": {},
   "source": [
    "Shuffling the database to remove bias and randomize the data and also removing the blank values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a432e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "df = df.replace(r' ', np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577d650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04c2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:4457,:]\n",
    "test_df = df.iloc[4458:5572,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2457188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f844da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>ham</td>\n",
       "      <td>He says he'll give me a call when his friend's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight should I just plan to come up later toni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>ham</td>\n",
       "      <td>Or u ask they all if next sat can a not. If al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ham</td>\n",
       "      <td>it's really getting me down just hanging around.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good good, billy mates all gone. Just been jog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup ok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>ham</td>\n",
       "      <td>Becoz its  &amp;lt;#&amp;gt;  jan whn al the post ofic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>ham</td>\n",
       "      <td>All was well until slightly disastrous class t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. It's not pride. I'm almost  &amp;lt;#&amp;gt;  yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>ham</td>\n",
       "      <td>Me hungry buy some food good lei... But mum n ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  ids\n",
       "313       ham  He says he'll give me a call when his friend's...    0\n",
       "4458      ham  Aight should I just plan to come up later toni...    0\n",
       "4794      ham  Or u ask they all if next sat can a not. If al...    0\n",
       "796       ham   it's really getting me down just hanging around.    0\n",
       "4305      ham  Good good, billy mates all gone. Just been jog...    0\n",
       "...       ...                                                ...  ...\n",
       "4963      ham                                          Yup ok...    0\n",
       "1911      ham  Becoz its  &lt;#&gt;  jan whn al the post ofic...    0\n",
       "407       ham  All was well until slightly disastrous class t...    0\n",
       "5335      ham  No. It's not pride. I'm almost  &lt;#&gt;  yea...    0\n",
       "3953      ham  Me hungry buy some food good lei... But mum n ...    0\n",
       "\n",
       "[1114 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2579a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAE/CAYAAADohqLkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU1ElEQVR4nO3df6hf933f8eersuuIpV5sfG0UXTGJoIzKHpXni6oRxtKkzFqSTg7DndwuVsGgYGyWskJrd4O4A4EHTVPczAZlMZbXNopGWyxaq63jJZSAY/U6qJZlx8uldu1rCesmXYkNRYvk9/74fkS/yF/rfvXrc389H3A45/s+n8/3fM4fX73uOefz/SpVhSRJ6uPHFnoAkiStJAavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdXTFuwySrgGngjar6VJJrga8B64FXgZ+vqv/b2t4P3AWcBv5jVf1Zq98CPAasBp4EPlfzfJ/puuuuq/Xr15/XSUmStNCee+6571fVxNn1sYMX+BzwEnB1e30f8HRVPZjkvvb615JsAnYANwIfBL6e5MNVdRp4BNgFfJtB8G4DDp7roOvXr2d6evo8hilJ0sJL8jej6mPdak4yCXwS+B9D5e3A3ra9F7htqL6vqk5W1SvADLAlyRrg6qp6pl3lPj7UR5KkFWHcZ7y/Dfwq8M5Q7YaqOg7Q1te3+lrg9aF2s622tm2fXZckacWYN3iTfAo4UVXPjfmeGVGrc9RHHXNXkukk03Nzc2MeVpKkxW+cK96PAP82yavAPuBjSX4XeLPdPqatT7T2s8C6of6TwLFWnxxRf5eq2lNVU1U1NTHxrufSkiQtWfMGb1XdX1WTVbWewaSp/11V/wE4AOxszXYCT7TtA8COJFcl2QBsBA6129FvJdmaJMCdQ30kSVoRzmdW89keBPYnuQt4DbgdoKqOJtkPvAicAu5pM5oB7uYfvk50kHlmNEuStNxksf+3gFNTU+XXiSRJS02S56pq6uy6v1wlSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHF/N1oiVn/X1/stBDkC7Iqw9+cqGHIOkS8YpXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSO5g3eJO9LcijJXyU5muQ3Wv2BJG8kOdyWTwz1uT/JTJKXk9w6VL8lyZG276EkuTynJUnS4nTFGG1OAh+rqreTXAl8K8nBtu+LVfWbw42TbAJ2ADcCHwS+nuTDVXUaeATYBXwbeBLYBhxEkqQVYt4r3hp4u728si11ji7bgX1VdbKqXgFmgC1J1gBXV9UzVVXA48BtFzV6SZKWmLGe8SZZleQwcAJ4qqqebbvuTfJ8kkeTXNNqa4HXh7rPttratn12fdTxdiWZTjI9Nzc3/tlIkrTIjRW8VXW6qjYDkwyuXm9icNv4Q8Bm4DjwhdZ81HPbOkd91PH2VNVUVU1NTEyMM0RJkpaE85rVXFV/B3wT2FZVb7ZAfgf4MrClNZsF1g11mwSOtfrkiLokSSvGOLOaJ5J8oG2vBn4W+G57ZnvGp4EX2vYBYEeSq5JsADYCh6rqOPBWkq1tNvOdwBOX7lQkSVr8xpnVvAbYm2QVg6DeX1V/nOR/JtnM4Hbxq8BnAarqaJL9wIvAKeCeNqMZ4G7gMWA1g9nMzmiWJK0o8wZvVT0P3Dyi/plz9NkN7B5RnwZuOs8xSpK0bPjLVZIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLU0bzBm+R9SQ4l+askR5P8Rqtfm+SpJN9r62uG+tyfZCbJy0luHarfkuRI2/dQklye05IkaXEa54r3JPCxqvopYDOwLclW4D7g6araCDzdXpNkE7ADuBHYBjycZFV7r0eAXcDGtmy7dKciSdLiN2/w1sDb7eWVbSlgO7C31fcCt7Xt7cC+qjpZVa8AM8CWJGuAq6vqmaoq4PGhPpIkrQhjPeNNsirJYeAE8FRVPQvcUFXHAdr6+tZ8LfD6UPfZVlvbts+uS5K0YowVvFV1uqo2A5MMrl5vOkfzUc9t6xz1d79BsivJdJLpubm5cYYoSdKScF6zmqvq74BvMng2+2a7fUxbn2jNZoF1Q90mgWOtPjmiPuo4e6pqqqqmJiYmzmeIkiQtauPMap5I8oG2vRr4WeC7wAFgZ2u2E3iibR8AdiS5KskGBpOoDrXb0W8l2dpmM9851EeSpBXhijHarAH2tpnJPwbsr6o/TvIMsD/JXcBrwO0AVXU0yX7gReAUcE9VnW7vdTfwGLAaONgWSZJWjHmDt6qeB24eUf8B8PH36LMb2D2iPg2c6/mwJEnLmr9cJUlSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHU0b/AmWZfkG0leSnI0yeda/YEkbyQ53JZPDPW5P8lMkpeT3DpUvyXJkbbvoSS5PKclSdLidMUYbU4Bv1JV30nyE8BzSZ5q+75YVb853DjJJmAHcCPwQeDrST5cVaeBR4BdwLeBJ4FtwMFLcyqSJC1+817xVtXxqvpO234LeAlYe44u24F9VXWyql4BZoAtSdYAV1fVM1VVwOPAbRd7ApIkLSXn9Yw3yXrgZuDZVro3yfNJHk1yTautBV4f6jbbamvb9tn1UcfZlWQ6yfTc3Nz5DFGSpEVt7OBN8n7gD4BfrqofMrht/CFgM3Ac+MKZpiO61znq7y5W7amqqaqampiYGHeIkiQtemMFb5IrGYTu71XVHwJU1ZtVdbqq3gG+DGxpzWeBdUPdJ4FjrT45oi5J0ooxzqzmAF8BXqqq3xqqrxlq9mnghbZ9ANiR5KokG4CNwKGqOg68lWRre887gScu0XlIkrQkjDOr+SPAZ4AjSQ632q8DdyTZzOB28avAZwGq6miS/cCLDGZE39NmNAPcDTwGrGYwm9kZzZKkFWXe4K2qbzH6+eyT5+izG9g9oj4N3HQ+A5QkaTnxl6skSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6MnglSerI4JUkqaN5gzfJuiTfSPJSkqNJPtfq1yZ5Ksn32vqaoT73J5lJ8nKSW4fqtyQ50vY9lCSX57QkSVqcxrniPQX8SlX9JLAVuCfJJuA+4Omq2gg83V7T9u0AbgS2AQ8nWdXe6xFgF7CxLdsu4blIkrTozRu8VXW8qr7Ttt8CXgLWAtuBva3ZXuC2tr0d2FdVJ6vqFWAG2JJkDXB1VT1TVQU8PtRHkqQV4bye8SZZD9wMPAvcUFXHYRDOwPWt2Vrg9aFus622tm2fXZckacUYO3iTvB/4A+CXq+qH52o6olbnqI861q4k00mm5+bmxh2iJEmL3ljBm+RKBqH7e1X1h638Zrt9TFufaPVZYN1Q90ngWKtPjqi/S1XtqaqpqpqamJgY91wkSVr0xpnVHOArwEtV9VtDuw4AO9v2TuCJofqOJFcl2cBgEtWhdjv6rSRb23veOdRHkqQV4Yox2nwE+AxwJMnhVvt14EFgf5K7gNeA2wGq6miS/cCLDGZE31NVp1u/u4HHgNXAwbZIkrRizBu8VfUtRj+fBfj4e/TZDeweUZ8GbjqfAUqStJz4y1WSJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSRwavJEkdGbySJHVk8EqS1JHBK0lSR/MGb5JHk5xI8sJQ7YEkbyQ53JZPDO27P8lMkpeT3DpUvyXJkbbvoSS59KcjSdLiNs4V72PAthH1L1bV5rY8CZBkE7ADuLH1eTjJqtb+EWAXsLEto95TkqRlbd7graq/AP52zPfbDuyrqpNV9QowA2xJsga4uqqeqaoCHgduu8AxS5K0ZF3MM957kzzfbkVf02prgdeH2sy22tq2fXZ9pCS7kkwnmZ6bm7uIIUqStLhcaPA+AnwI2AwcB77Q6qOe29Y56iNV1Z6qmqqqqYmJiQscoiRJi88FBW9VvVlVp6vqHeDLwJa2axZYN9R0EjjW6pMj6pIkrSgXFLztme0ZnwbOzHg+AOxIclWSDQwmUR2qquPAW0m2ttnMdwJPXMS4JUlakq6Yr0GSrwIfBa5LMgt8Hvhoks0Mbhe/CnwWoKqOJtkPvAicAu6pqtPtre5mMEN6NXCwLZIkrSjzBm9V3TGi/JVztN8N7B5RnwZuOq/RSZK0zPjLVZIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLUkcErSVJHBq8kSR0ZvJIkdWTwSpLU0bzBm+TRJCeSvDBUuzbJU0m+19bXDO27P8lMkpeT3DpUvyXJkbbvoSS59KcjSdLiNs4V72PAtrNq9wFPV9VG4On2miSbgB3Aja3Pw0lWtT6PALuAjW05+z0lSVr25g3eqvoL4G/PKm8H9rbtvcBtQ/V9VXWyql4BZoAtSdYAV1fVM1VVwONDfSRJWjEu9BnvDVV1HKCtr2/1tcDrQ+1mW21t2z67LknSinKpJ1eNem5b56iPfpNkV5LpJNNzc3OXbHCSJC20Cw3eN9vtY9r6RKvPAuuG2k0Cx1p9ckR9pKraU1VTVTU1MTFxgUOUJGnxudDgPQDsbNs7gSeG6juSXJVkA4NJVIfa7ei3kmxts5nvHOojSdKKccV8DZJ8FfgocF2SWeDzwIPA/iR3Aa8BtwNU1dEk+4EXgVPAPVV1ur3V3QxmSK8GDrZFkqQVZd7grao73mPXx9+j/W5g94j6NHDTeY1OkqRlxl+ukiSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6sjglSSpI4NXkqSODF5JkjoyeCVJ6uiKhR6ApOVn/X1/stBDkM7bqw9+sstxvOKVJKkjg1eSpI4uKniTvJrkSJLDSaZb7dokTyX5XltfM9T+/iQzSV5OcuvFDl6SpKXmUlzx/kxVba6qqfb6PuDpqtoIPN1ek2QTsAO4EdgGPJxk1SU4viRJS8bluNW8HdjbtvcCtw3V91XVyap6BZgBtlyG40uStGhdbPAW8OdJnkuyq9VuqKrjAG19fauvBV4f6jvbau+SZFeS6STTc3NzFzlESZIWj4v9OtFHqupYkuuBp5J89xxtM6JWoxpW1R5gD8DU1NTINpIkLUUXdcVbVcfa+gTwRwxuHb+ZZA1AW59ozWeBdUPdJ4FjF3N8SZKWmgsO3iT/KMlPnNkG/jXwAnAA2Nma7QSeaNsHgB1JrkqyAdgIHLrQ40uStBRdzK3mG4A/SnLmfX6/qv40yV8C+5PcBbwG3A5QVUeT7AdeBE4B91TV6YsavSRJS8wFB29V/TXwUyPqPwA+/h59dgO7L/SYkiQtdf5ylSRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR1ZPBKktSRwStJUkcGryRJHRm8kiR11D14k2xL8nKSmST39T6+JEkLqWvwJlkF/Hfg3wCbgDuSbOo5BkmSFlLvK94twExV/XVV/T9gH7C98xgkSVowvYN3LfD60OvZVpMkaUW4ovPxMqJW72qU7AJ2tZdvJ3n5so5Kl8p1wPcXehDLUf7bQo9Ai4ifs8vkMnzO/smoYu/gnQXWDb2eBI6d3aiq9gB7eg1Kl0aS6aqaWuhxSMuZn7Olr/et5r8ENibZkOTHgR3Agc5jkCRpwXS94q2qU0nuBf4MWAU8WlVHe45BkqSF1PtWM1X1JPBk7+OqCx8PSJefn7MlLlXvmtskSZIuE38yUpKkjgxenVOSt896/UtJvrRQ45GWkyT/OcnRJM8nOZzkpxd6TLr8uj/jlSRBkn8BfAr451V1Msl1wI8v8LDUgcGrC5bk54D/wuAfix8Av1hVbyZ5ANgArAE+DPwnYCuD3+h+A/i5qvrRggxaWjzWAN+vqpMAVfV9gCSvAl8Dfqa1+4WqmvHztnx4q1nzWd1ugR1Ochj4r0P7vgVsraqbGfzu9q8O7fsQ8EkGv8X9u8A3quqfAX/f6tJK9+fAuiT/J8nDSf7V0L4fVtUW4EvAb7ean7dlwitezefvq2rzmRdJfgk486s5k8DXkqxh8Ff4K0P9DlbVj5IcYfCd7T9t9SPA+ss8ZmnRq6q3k9wC/EsGV7dfG/qvUr86tP5i2/bztkx4xauL8TvAl9pf1p8F3je078zts3eAH9U/fG/tHfyDTwKgqk5X1Ter6vPAvcC/O7NruFlb+3lbJgxeXYx/zOAZEsDOhRyItNQk+adJNg6VNgN/07b//dD6mbbt522Z8C8hXYwHgP+V5A3g2wwmeEgaz/uB30nyAeAUMMPgf2X7FHBVkmcZXBzd0do/gJ+3ZcFfrpKkRaTNap46M8tZy4+3miVJ6sgrXkmSOvKKV5KkjgxeSZI6MnglSerI4JUkqSODV5KkjgxeSZI6+v+ClZOWpcohOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ham, spam = train_df['Category'].value_counts()\n",
    "Mess_type = ['Ham', 'Spam']\n",
    "Mess_count = [ham, spam]\n",
    "ax.bar(Mess_type, Mess_count)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bee443",
   "metadata": {},
   "source": [
    "Our training set is imbalanced and hence there are high chances that bias could be induced in our training model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012ae26",
   "metadata": {},
   "source": [
    "Converting the all the text to lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4054633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_2690/1326804694.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Message'] = train_df['Message'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "train_df['Message'] = train_df['Message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4bd47f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>ham</td>\n",
       "      <td>u really pig leh sleep so much. my dad wake me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>ham</td>\n",
       "      <td>i did. one slice and one breadstick. lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>ham</td>\n",
       "      <td>i love to wine and dine my lady!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>ham</td>\n",
       "      <td>actually nvm, got hella cash, we still on for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ham</td>\n",
       "      <td>hi babe im at home now wanna do something? xx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>ham</td>\n",
       "      <td>university of southern california.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>ham</td>\n",
       "      <td>check mail.i have mailed varma and kept copy t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>ham</td>\n",
       "      <td>just checked out, heading out to drop off my s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>ham</td>\n",
       "      <td>don no da:)whats you plan?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>spam</td>\n",
       "      <td>ringtone club: gr8 new polys direct to your mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  ids\n",
       "4232      ham  u really pig leh sleep so much. my dad wake me...    0\n",
       "2061      ham           i did. one slice and one breadstick. lol    0\n",
       "1744      ham                   i love to wine and dine my lady!    0\n",
       "3800      ham  actually nvm, got hella cash, we still on for ...    0\n",
       "72        ham      hi babe im at home now wanna do something? xx    0\n",
       "...       ...                                                ...  ...\n",
       "4021      ham                 university of southern california.    0\n",
       "4944      ham  check mail.i have mailed varma and kept copy t...    0\n",
       "2257      ham  just checked out, heading out to drop off my s...    0\n",
       "4699      ham                         don no da:)whats you plan?    0\n",
       "3988     spam  ringtone club: gr8 new polys direct to your mo...    1\n",
       "\n",
       "[4457 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0ca50",
   "metadata": {},
   "source": [
    "# Removing stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf1d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_2690/3706990871.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Message'] = train_df['Message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # we will match words in ur text to the ones from the list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4232    u really pig leh sleep much. dad wake 10 smth ...\n",
       "2061                   did. one slice one breadstick. lol\n",
       "1744                                 love wine dine lady!\n",
       "3800    actually nvm, got hella cash, still &lt;#&gt; ...\n",
       "72                    hi babe im home wanna something? xx\n",
       "                              ...                        \n",
       "4021                      university southern california.\n",
       "4944    check mail.i mailed varma kept copy regarding ...\n",
       "2257                      checked out, heading drop stuff\n",
       "4699                                      da:)whats plan?\n",
       "3988    ringtone club: gr8 new polys direct mobile eve...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "word = set(stopwords.words('english')) \n",
    "stop = stopwords.words('english') # Basically, we will save all the stop words collection in a list\n",
    "train_df['Message'] = train_df['Message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) # we will match words in ur text to the ones from the list\n",
    "train_df['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98e618",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6669709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_2690/2964377847.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Message'] = train_df['Message'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_2690/2964377847.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['Message'] = train_df['Message'].str.replace('[^\\w\\s]','')\n",
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_2690/2964377847.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Message'] = train_df['Message'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4232    u realli pig leh sleep much dad wake 10 smth 2...\n",
       "2061                     did one slice one breadstick lol\n",
       "1744                                  love wine dine lady\n",
       "3800             actual nvm got hella cash still ltgt ish\n",
       "72                     hi babe im home wanna something xx\n",
       "                              ...                        \n",
       "4021                          univers southern california\n",
       "4944    check maili mail varma kept copi regard member...\n",
       "2257                            check out head drop stuff\n",
       "4699                                          dawhat plan\n",
       "3988    rington club gr8 new poli direct mobil everi w...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "train_df['Message'] = train_df['Message'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "train_df['Message'] = train_df['Message'].str.replace('[^\\w\\s]','')\n",
    "train_df['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839748f",
   "metadata": {},
   "source": [
    "# Lemmetization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5cd4e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4232    u realli pig leh sleep much dad wake 10 smth 2...\n",
       "2061                     did one slice one breadstick lol\n",
       "1744                                  love wine dine lady\n",
       "3800             actual nvm got hella cash still ltgt ish\n",
       "72                     hi babe im home wanna something xx\n",
       "                              ...                        \n",
       "4021                          univers southern california\n",
       "4944    check maili mail varma kept copi regard member...\n",
       "2257                            check out head drop stuff\n",
       "4699                                          dawhat plan\n",
       "3988    rington club gr8 new poli direct mobil everi w...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np \n",
    "wordnet_lemm = WordNetLemmatizer()\n",
    "lemm_words = np.vectorize(wordnet_lemm.lemmatize)\n",
    "lemm_text = ' '.join(lemm_words(train_df['Message']))\n",
    "train_df['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c69f8",
   "metadata": {},
   "source": [
    "# Splitting words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d8f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u                 897\n",
       "call              514\n",
       "2                 376\n",
       "get               368\n",
       "im                361\n",
       "                 ... \n",
       "jamstercouk         1\n",
       "logosmusicnews      1\n",
       "videosounds2        1\n",
       "videosound          1\n",
       "careinsha           1\n",
       "Length: 7954, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.Series(' '.join(train_df['Message']).split()).value_counts()\n",
    "word_count.sample(10)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51750308",
   "metadata": {},
   "source": [
    "# TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f10f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', lowercase = True)\n",
    "# With this method we will split our text into one and two words combination. \n",
    "# Depending upon their usage and importance they will be assigned a value.  \n",
    "Message = tfidf.fit_transform(train_df['Message']).toarray()\n",
    "ids = train_df['ids']\n",
    "print(Message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b0147",
   "metadata": {},
   "source": [
    "# Chi Square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f6d3495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2\n",
    "kbest = SelectKBest(score_func = chi2, k = 500 ) # Here using the chi-square test, we will determine which top 500 features will be retained. \n",
    "best_ham = kbest.fit_transform(Message, ids)\n",
    "best_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38432fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(best_ham,ids, test_size = 0.3, random_state = 60,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03788dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1155\n",
      "           1       1.00      0.42      0.59       183\n",
      "\n",
      "    accuracy                           0.92      1338\n",
      "   macro avg       0.96      0.71      0.77      1338\n",
      "weighted avg       0.93      0.92      0.91      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we will first test MultinomialNB model without cross validation.\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "multi = MultinomialNB()\n",
    "multi.fit(X_train, Y_train) # fit method allows us to fit our data into the model \n",
    "Y_pred = multi.predict(X_test) # using predict() we will predict the dependent values for the corresponding independent variables.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca2fb3",
   "metadata": {},
   "source": [
    "Now we will use the same model but with k fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ce20c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9051034710198698, 0.010608008470652248)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "multi.fit(X_train, Y_train)\n",
    "scores = cross_val_score(multi, X_train, Y_train, cv=10)\n",
    "scores \n",
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d31be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
